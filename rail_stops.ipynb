{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from shapely.geometry import Point\n",
    "from fiona.crs import from_epsg\n",
    "import logging\n",
    "\n",
    "# configure logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.FileHandler(\"error_log.log\")\n",
    "handler.setLevel(logging.ERROR)\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "\n",
    "path_name = os.getcwd()\n",
    "folder = \"June2019\"\n",
    "\n",
    "rails = [\"LIRR\", \"metro_north\", \"nyc_subway\"]\n",
    "\n",
    "def make_stop_shapes(df, x=\"stop_lon\", y=\"stop_lat\"):\n",
    "    if df[x].isna().sum() > 0 or df[y].isna().sum() > 0:\n",
    "        raise \"DataFrame contains Null coordinates\"\n",
    "\n",
    "    points = [Point(xy) for xy in zip(df[x], df[y])]\n",
    "    gdf = gpd.GeoDataFrame(df, geometry=points)\n",
    "    gdf.crs = from_epsg(4269)  # initiate crs as NAD83\n",
    "    gdf = gdf.to_crs(epsg=2263)  # NY State Plane\n",
    "    return gdf\n",
    "\n",
    "\n",
    "# read-in file that idicates which trains stop at which stations\n",
    "trains_at_stops = pd.read_csv(\n",
    "    \"http://web.mta.info/developers/data/nyct/subway/Stations.csv\",\n",
    "    usecols=[\"GTFS Stop ID\", \"Daytime Routes\", \"Structure\"],\n",
    ")\n",
    "\n",
    "trains_at_stops.rename(\n",
    "    columns={\n",
    "        \"GTFS Stop ID\": \"stop_id\",\n",
    "        \"Daytime Routes\": \"trains\",\n",
    "        \"Structure\": \"structure\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "def make_rail_stops(path_name, folder, rail):\n",
    "    try:\n",
    "        file = os.path.join(path_name, folder, f\"{rail}\")\n",
    "        stops = pd.read_csv(\n",
    "            os.path.join(file, \"stops.txt\"),\n",
    "            usecols=[\"stop_id\", \"stop_name\", \"stop_lat\", \"stop_lon\"],\n",
    "        )\n",
    "\n",
    "        stops = stops.loc[\n",
    "            stops[\"stop_id\"].isin(\n",
    "                stops.stop_id.astype(str)\n",
    "                .str.rstrip(\"N\")\n",
    "                .str.rstrip(\"S\")\n",
    "                .unique()\n",
    "                .tolist()\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # correct coordinates of the station with id='H01'\n",
    "        stops.loc[stops[\"stop_id\"] == \"H01\", \"stop_lat\"] = 40.672086\n",
    "        stops.loc[stops[\"stop_id\"] == \"H01\", \"stop_lon\"] = -73.835914\n",
    "\n",
    "        df = stops.loc[stops.duplicated(subset=[\"stop_lat\", \"stop_lon\"])][\n",
    "            [\"stop_lat\", \"stop_lon\", \"stop_id\"]\n",
    "        ]  # get the duplciate stations only; columns specified\n",
    "        df.rename(\n",
    "            columns={\"stop_id\": \"stop_id2\"}, inplace=True\n",
    "        )  # rename the last column; it will be used as stop_id2 to reference the removed duplicates\n",
    "\n",
    "        if rail == \"nyc_subway\":\n",
    "            stops = (\n",
    "                stops.merge(trains_at_stops, on=\"stop_id\", how=\"outer\")\n",
    "                .drop_duplicates([\"stop_lat\", \"stop_lon\"], keep=\"first\")\n",
    "                .merge(df, on=[\"stop_lat\", \"stop_lon\"], how=\"left\")\n",
    "            )\n",
    "        elif rail == \"metro_north\":\n",
    "            metro_north_bus_stops = stops[\n",
    "                (stops[\"stop_id\"] > 500)\n",
    "                & (stops[\"stop_id\"] != 622)\n",
    "                & (stops[\"stop_id\"] < 1000)\n",
    "                | (stops[\"stop_id\"] == 14)\n",
    "                | (stops[\"stop_id\"] == 16)\n",
    "            ]\n",
    "            stops = stops.drop_duplicates([\"stop_lat\", \"stop_lon\"], keep=\"first\")\n",
    "        else:\n",
    "            stops = stops.drop_duplicates([\"stop_lat\", \"stop_lon\"], keep=\"first\")\n",
    "\n",
    "        stops_geo = make_stop_shapes(stops)\n",
    "        counties = gpd.read_file(\n",
    "            os.path.join(path_name, \"counties_bndry.geojson\"), driver=\"GeoJSON\"\n",
    "        )\n",
    "        counties = counties.to_crs(epsg=2263)\n",
    "        stops_geo = gpd.sjoin(stops_geo, counties, how=\"inner\", op=\"intersects\").drop(\n",
    "            \"index_right\", 1\n",
    "        )\n",
    "        stops_geo.to_file(\n",
    "            os.path.join(\n",
    "                path_name, folder, \"shapes\", f\"stops_{rail}_{folder.lower()}.shp\"\n",
    "            )\n",
    "        )\n",
    "        print (f\"Created stop shapefiles for {rail}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Unexpected exception occurred\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
