{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The blackcellmagic extension is already loaded. To reload it, use:\n",
      "  %reload_ext blackcellmagic\n"
     ]
    }
   ],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue May 23 09:09:26 2017\n",
    "\n",
    "This script downloads the GTFS data feeds and \n",
    "places them into corresponding folders. The dates of the MTA\n",
    "updates are written into updates.txt file.\n",
    "\n",
    "@author: AClark\n",
    "last updated on : May 18, 2018\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, os\n",
    "import zipfile\n",
    "import logging\n",
    "\n",
    "# configure logger\n",
    "logger = logging.getLogger(__name__)\n",
    "handler = logging.FileHandler(\"data_log.log\")\n",
    "logger.setLevel(logging.INFO)\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "\n",
    "def get_gtfs_data(new_folder_name):\n",
    "    \"\"\"Download the GTFS data feeds and places them into corresponding folders. The dates of the MTA\n",
    "    updates are written into updates.txt file.\n",
    "    \n",
    "    params:\n",
    "        new_folder_name (str): Name of the folder where downloaded data will be stored\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # server_path=r'\\\\DFSN1V-B\\Shares\\LibShare\\Shared\\Divisions\\Graduate\\GEODATA\\MASS_Transit'\n",
    "        server_path = os.getcwd()\n",
    "        base_path = \"http://web.mta.info/developers\"\n",
    "\n",
    "        folders_to_create = [\n",
    "            \"nyc_subway\",\n",
    "            \"bk_bus\",\n",
    "            \"qn_bus\",\n",
    "            \"bus_company\",\n",
    "            \"bx_bus\",\n",
    "            \"si_bus\",\n",
    "            \"mn_bus\",\n",
    "            \"LIRR\",\n",
    "            \"metro_north\",\n",
    "            \"shapes\",\n",
    "        ]\n",
    "\n",
    "        folders_match = {\n",
    "            \"Bus Company\": \"bus_company\",\n",
    "            \"Long Island Rail Road\": \"LIRR\",\n",
    "            \"Metro-North Railroad\": \"metro_north\",\n",
    "            \"Bronx\": \"bx_bus\",\n",
    "            \"Brooklyn\": \"bk_bus\",\n",
    "            \"Manhattan\": \"mn_bus\",\n",
    "            \"Queens\": \"qn_bus\",\n",
    "            \"Staten Island\": \"si_bus\",\n",
    "            \"New York City Transit Subway\": \"nyc_subway\",\n",
    "        }\n",
    "\n",
    "        for folder in folders_to_create:\n",
    "            if not os.path.exists(os.path.join(server_path, new_folder_name, folder)):\n",
    "                os.makedirs(os.path.join(server_path, new_folder_name, folder))\n",
    "\n",
    "        url = \"http://web.mta.info/developers/developer-data-terms.html#data\"\n",
    "        r = requests.get(url)\n",
    "        data = r.text\n",
    "        soup = BeautifulSoup(data, \"html\", features=\"lxml\")\n",
    "\n",
    "        # get all `li` elements\n",
    "        lis = soup.find_all(\"li\")\n",
    "\n",
    "        # find links and their associated texts in li elements\n",
    "        all_links = {\n",
    "            l.find(\"a\").get(\"href\"): [l.text, l.find(\"a\").text]\n",
    "            for l in lis\n",
    "            if l.find(\"a\") and l.text\n",
    "        }\n",
    "\n",
    "        # get links of the GTFS static feeds only\n",
    "        gtfs = [\n",
    "            k\n",
    "            for k in all_links.keys()\n",
    "            if k\n",
    "            and \".zip\" in k\n",
    "            and k.startswith(\"data\")\n",
    "            and \"Shapefiles\" not in k\n",
    "            and \"Historical\" not in k\n",
    "        ]\n",
    "\n",
    "        # place link and the cleaned-up text of the link in a dictionary\n",
    "        gtfs_d = {l: all_links[l][1].strip(\"-\").strip() for l in gtfs}\n",
    "\n",
    "        # get the info when the GTF feed was updated\n",
    "        updates = {l: all_links[l][0] for l in gtfs}\n",
    "        dates = [v for v in updates.values()]\n",
    "        dates_fromatted = [\" \".join(d.split()) for d in dates]\n",
    "\n",
    "        print(\"Downloading the data.............\")\n",
    "        # download and unzip the data into its appropriate folders\n",
    "        for k, v in gtfs_d.items():\n",
    "            name = \"{}.zip\".format(folders_match[v])\n",
    "            urllib.request.urlretrieve(\n",
    "                f\"{base_path}/{k}\",\n",
    "                os.path.join(server_path, new_folder_name, folders_match[v], name),\n",
    "            )\n",
    "            zip_ref = zipfile.ZipFile(\n",
    "                os.path.join(server_path, new_folder_name, folders_match[v], name), \"r\"\n",
    "            )\n",
    "            zip_ref.extractall(\n",
    "                os.path.join(server_path, new_folder_name, folders_match[v])\n",
    "            )\n",
    "            zip_ref.close()\n",
    "\n",
    "        # write out the dates of the latest update by MTA for each data downloaded\n",
    "        with open(os.path.join(server_path, new_folder_name, \"updates.txt\"), \"w\") as t:\n",
    "            for line in dates_fromatted:\n",
    "                t.write(line + \"\\n\")\n",
    "\n",
    "        print(\"Done!\", \"Check the\", new_folder_name, \"folder\")\n",
    "        logger.info(f\"Downloaded GTFS data from {base_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Unexpected exception occurred\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
